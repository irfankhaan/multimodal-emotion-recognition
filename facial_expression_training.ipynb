{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import pandas as pd\r\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Final/'\r\n",
    "files = []\r\n",
    "# r=root, d=directories, f = files\r\n",
    "for r, d, f in os.walk(path):\r\n",
    "    for file in f:\r\n",
    "        if '.csv' in file:\r\n",
    "            files.append(os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Final/927_0196_01.csv',\n",
       " 'Final/927_0197_01.csv',\n",
       " 'Final/927_0198_01.csv',\n",
       " 'Final/927_0199_01.csv',\n",
       " 'Final/927_0200_01.csv',\n",
       " 'Final/927_0201_01.csv',\n",
       " 'Final/927_0202_01.csv',\n",
       " 'Final/927_0212_01.csv',\n",
       " 'Final/927_0213_01.csv',\n",
       " 'Final/927_0214_01.csv',\n",
       " 'Final/927_0215_01.csv',\n",
       " 'Final/927_0216_01.csv',\n",
       " 'Final/927_0217_01.csv',\n",
       " 'Final/927_0218_01.csv',\n",
       " 'Final/927_0219_01.csv',\n",
       " 'Final/927_0220_01.csv',\n",
       " 'Final/927_0221_01.csv',\n",
       " 'Final/927_0222_01.csv',\n",
       " 'Final/927_0223_01.csv',\n",
       " 'Final/927_0224_01.csv',\n",
       " 'Final/927_0225_01.csv',\n",
       " 'Final/927_0226_01.csv',\n",
       " 'Final/927_0227_01.csv',\n",
       " 'Final/927_0228_01.csv',\n",
       " 'Final/927_0229_01.csv',\n",
       " 'Final/927_0230_01.csv',\n",
       " 'Final/927_0231_01.csv',\n",
       " 'Final/927_0232_01.csv',\n",
       " 'Final/927_0233_01.csv',\n",
       " 'Final/927_0234_01.csv',\n",
       " 'Final/927_0235_01.csv',\n",
       " 'Final/927_0236_01.csv',\n",
       " 'Final/927_0237_01.csv',\n",
       " 'Final/927_0239_01.csv',\n",
       " 'Final/927_0240_01.csv',\n",
       " 'Final/927_0241_01.csv',\n",
       " 'Final/927_0242_01.csv',\n",
       " 'Final/927_0243_01.csv',\n",
       " 'Final/927_0244_01.csv',\n",
       " 'Final/927_0245_01.csv',\n",
       " 'Final/927_0246_01.csv',\n",
       " 'Final/927_0247_01.csv',\n",
       " 'Final/927_0248_01.csv',\n",
       " 'Final/927_0249_01.csv',\n",
       " 'Final/927_0250_01.csv',\n",
       " 'Final/927_0251_01.csv',\n",
       " 'Final/927_0252_01.csv',\n",
       " 'Final/927_0253_01.csv',\n",
       " 'Final/927_0254_01.csv',\n",
       " 'Final/927_0269_01.csv',\n",
       " 'Final/927_0270_01.csv',\n",
       " 'Final/927_0271_01.csv',\n",
       " 'Final/927_0272_01.csv',\n",
       " 'Final/927_0273_01.csv',\n",
       " 'Final/927_0274_01.csv',\n",
       " 'Final/927_0275_01.csv',\n",
       " 'Final/927_0276_01.csv',\n",
       " 'Final/927_0277_01.csv',\n",
       " 'Final/927_0278_01.csv',\n",
       " 'Final/927_0279_01.csv',\n",
       " 'Final/927_0280_01.csv',\n",
       " 'Final/927_0281_01.csv',\n",
       " 'Final/927_0282_01.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_no</th>\n",
       "      <th>output</th>\n",
       "      <th>expression_index</th>\n",
       "      <th>video_name</th>\n",
       "      <th>start_time_in_sec</th>\n",
       "      <th>end_time_in_sec</th>\n",
       "      <th>start_exp</th>\n",
       "      <th>end_exp</th>\n",
       "      <th>text_file</th>\n",
       "      <th>kinect_start_frame</th>\n",
       "      <th>kinect_end_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>An</td>\n",
       "      <td>1</td>\n",
       "      <td>927_0216_01.MP4</td>\n",
       "      <td>5.356700</td>\n",
       "      <td>9.481139</td>\n",
       "      <td>161</td>\n",
       "      <td>284</td>\n",
       "      <td>20170902_092359_00.txt</td>\n",
       "      <td>217</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>An</td>\n",
       "      <td>2</td>\n",
       "      <td>927_0216_01.MP4</td>\n",
       "      <td>9.883585</td>\n",
       "      <td>14.903150</td>\n",
       "      <td>296</td>\n",
       "      <td>447</td>\n",
       "      <td>20170902_092359_00.txt</td>\n",
       "      <td>322</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>An</td>\n",
       "      <td>3</td>\n",
       "      <td>927_0216_01.MP4</td>\n",
       "      <td>14.903150</td>\n",
       "      <td>19.427206</td>\n",
       "      <td>447</td>\n",
       "      <td>582</td>\n",
       "      <td>20170902_092359_00.txt</td>\n",
       "      <td>466</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>An</td>\n",
       "      <td>4</td>\n",
       "      <td>927_0216_01.MP4</td>\n",
       "      <td>19.427206</td>\n",
       "      <td>25.077029</td>\n",
       "      <td>582</td>\n",
       "      <td>752</td>\n",
       "      <td>20170902_092359_00.txt</td>\n",
       "      <td>564</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>An</td>\n",
       "      <td>5</td>\n",
       "      <td>927_0216_01.MP4</td>\n",
       "      <td>25.077029</td>\n",
       "      <td>29.981168</td>\n",
       "      <td>752</td>\n",
       "      <td>899</td>\n",
       "      <td>20170902_092359_00.txt</td>\n",
       "      <td>699</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  gender_no output  expression_index       video_name  \\\n",
       "1      F          3     An                 1  927_0216_01.MP4   \n",
       "2      F          3     An                 2  927_0216_01.MP4   \n",
       "3      F          3     An                 3  927_0216_01.MP4   \n",
       "4      F          3     An                 4  927_0216_01.MP4   \n",
       "5      F          3     An                 5  927_0216_01.MP4   \n",
       "\n",
       "   start_time_in_sec  end_time_in_sec  start_exp  end_exp  \\\n",
       "1           5.356700         9.481139        161      284   \n",
       "2           9.883585        14.903150        296      447   \n",
       "3          14.903150        19.427206        447      582   \n",
       "4          19.427206        25.077029        582      752   \n",
       "5          25.077029        29.981168        752      899   \n",
       "\n",
       "                text_file  kinect_start_frame  kinect_end_frame  \n",
       "1  20170902_092359_00.txt                 217               312  \n",
       "2  20170902_092359_00.txt                 322               466  \n",
       "3  20170902_092359_00.txt                 466               564  \n",
       "4  20170902_092359_00.txt                 564               699  \n",
       "5  20170902_092359_00.txt                 699               828  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors = pd.read_csv('Descriptors.csv', index_col=0)\r\n",
    "descriptors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file):\r\n",
    "    temp_df = pd.read_csv(file, sep=',')\r\n",
    "    temp_df.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
    "    max_value = np.amax(temp_df)\r\n",
    "    max_value = max(max_value)\r\n",
    "    temp_df = temp_df/max_value\r\n",
    "    #print(max_value)\r\n",
    "    name = file[6:-4]\r\n",
    "    output_value = descriptors.loc[descriptors['video_name']==name +'.MP4']['output'][:1].values[0]\r\n",
    "    #video_name = descriptors.loc[descriptors['text_file']==textfile]['video_name'][:1].values[0]\r\n",
    "    gender = descriptors.loc[descriptors['video_name']==name +'.MP4']['gender'][:1].values[0]\r\n",
    "    #temp_df['textfile'] = textfile\r\n",
    "    #temp_df['output'] = output_value\r\n",
    "    #temp_df['video_name'] = video_name\r\n",
    "    if gender == 'F':\r\n",
    "        temp_df['gender'] = 1\r\n",
    "    else:\r\n",
    "        temp_df['gender'] = 0\r\n",
    "    #temp_df.drop(['Unnamed: 152'], axis=1, inplace=True)\r\n",
    "    return temp_df.values, output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = load_file('Final/927_0196_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 2279)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\r\n",
    "Y = []\r\n",
    "for name in files:\r\n",
    "    data, t = load_file(name)\r\n",
    "    shapes.append(data.shape[0])\r\n",
    "    Y.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0 \r\n",
    "for element in Y:\r\n",
    "    if element == 'Ne':\r\n",
    "        Y[index] = 0\r\n",
    "    elif element == 'Sa':\r\n",
    "        Y[index] = 1\r\n",
    "    elif element == 'Su':\r\n",
    "        Y[index] = 2\r\n",
    "    elif element == 'Fe':\r\n",
    "        Y[index] = 3\r\n",
    "    elif element == 'An':\r\n",
    "        Y[index] = 4\r\n",
    "    elif element == 'Di':\r\n",
    "        Y[index] = 5\r\n",
    "    elif element == 'Ha':\r\n",
    "        Y[index] = 6\r\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\r\n",
    "\r\n",
    "maxlen = max(shapes)\r\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group(filenames, prefix=''):\r\n",
    "    loaded = list()\r\n",
    "    for name in filenames:\r\n",
    "        data, temp = load_file(name)\r\n",
    "        #print('The name is:', name, data.shape)\r\n",
    "        zeros_data = np.zeros((max(shapes)-data.shape[0], 2279))\r\n",
    "        print(data.shape)\r\n",
    "        data = np.concatenate((zeros_data, data), axis=0)\r\n",
    "        #print('Now the shape is:', name, data.shape)\r\n",
    "        loaded.append(data)\r\n",
    "        shapes.append(data.shape[0])\r\n",
    "    loaded = np.stack(loaded)\r\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 2279)\n",
      "(1068, 2279)\n",
      "(1113, 2279)\n",
      "(1363, 2279)\n",
      "(966, 2279)\n",
      "(1254, 2279)\n",
      "(1028, 2279)\n",
      "(1036, 2279)\n",
      "(1420, 2279)\n",
      "(1322, 2279)\n",
      "(1351, 2279)\n",
      "(953, 2279)\n",
      "(1311, 2279)\n",
      "(908, 2279)\n",
      "(915, 2279)\n",
      "(1132, 2279)\n",
      "(973, 2279)\n",
      "(920, 2279)\n",
      "(1084, 2279)\n",
      "(1046, 2279)\n",
      "(1023, 2279)\n",
      "(843, 2279)\n",
      "(951, 2279)\n",
      "(1266, 2279)\n",
      "(797, 2279)\n",
      "(824, 2279)\n",
      "(781, 2279)\n",
      "(739, 2279)\n",
      "(896, 2279)\n",
      "(1124, 2279)\n",
      "(1022, 2279)\n",
      "(1175, 2279)\n",
      "(853, 2279)\n",
      "(870, 2279)\n",
      "(724, 2279)\n",
      "(793, 2279)\n",
      "(757, 2279)\n",
      "(777, 2279)\n",
      "(744, 2279)\n",
      "(744, 2279)\n",
      "(1605, 2279)\n",
      "(576, 2279)\n",
      "(837, 2279)\n",
      "(1147, 2279)\n",
      "(1106, 2279)\n",
      "(1175, 2279)\n",
      "(734, 2279)\n",
      "(1166, 2279)\n",
      "(682, 2279)\n",
      "(1061, 2279)\n",
      "(1098, 2279)\n",
      "(950, 2279)\n",
      "(1296, 2279)\n",
      "(842, 2279)\n",
      "(1183, 2279)\n",
      "(959, 2279)\n",
      "(1865, 2279)\n",
      "(1578, 2279)\n",
      "(1150, 2279)\n",
      "(1225, 2279)\n",
      "(886, 2279)\n",
      "(1333, 2279)\n",
      "(1056, 2279)\n",
      "(63, 1865, 2279) (63, 7)\n"
     ]
    }
   ],
   "source": [
    "X = load_group(files)\r\n",
    "\r\n",
    "Y = np.asarray(Y).reshape((63,1))\r\n",
    "Y = to_categorical(Y)\r\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\r\n",
    "from tensorflow.keras import regularizers\r\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\r\n",
    "    verbose = 1\r\n",
    "    epochs = 100\r\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\r\n",
    "    model = Sequential()\r\n",
    "    model.add(LSTM(32, input_shape=(n_timesteps, n_features)))\r\n",
    "    #model.add(Dropout(0.5))\r\n",
    "    #model.add(Dense(16, activation=partial(tf.nn.leaky_relu, alpha=0.01)))\r\n",
    "    model.add(Dense(16, activation='relu'))\r\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\r\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\r\n",
    "    model.fit(trainX, trainy, epochs=epochs, verbose=verbose)\r\n",
    "    _, accuracy = model.evaluate(testX, testy, verbose=verbose)\r\n",
    "    return accuracy, model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-048563376743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abc43c0dfd3be6e75395e609b68ff1d444fe1ba7bc598f9a4d8e0d29e2c56ec5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tensorflow-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}